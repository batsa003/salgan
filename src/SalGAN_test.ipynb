{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from data_loader import DataLoader\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch_size = 3\n",
    "dataloader = DataLoader(batch_size)\n",
    "\n",
    "def show(img):\n",
    "    print(img.shape)\n",
    "    pilTrans = transforms.ToPILImage()\n",
    "    pilImg = pilTrans(img)\n",
    "    s = np.array(pilImg)\n",
    "    plt.figure()\n",
    "    plt.imshow(s)\n",
    "\n",
    "for i in range(2):\n",
    "    (b_img, b_map) = dataloader.get_batch()\n",
    "    show(b_img[0])\n",
    "    show(b_img[1])\n",
    "    show(b_img[2])\n",
    "    show(b_map[0])\n",
    "    show(b_map[1])\n",
    "    show(b_map[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from discriminator import Discriminator\n",
    "from generator import Generator\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "batch_size = 10\n",
    "lr = 0.0003\n",
    "\n",
    "discriminator = Discriminator()\n",
    "generator = Generator()\n",
    "if torch.cuda.is_available():\n",
    "    discriminator.cuda()\n",
    "    generator.cuda()\n",
    "loss_function = nn.BCELoss()\n",
    "\n",
    "d_optim = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
    "g_optim = torch.optim.Adam(generator.parameters(), lr=lr)\n",
    "\n",
    "num_epoch = 1\n",
    "dataloader = DataLoader(batch_size)\n",
    "num_batch = dataloader.num_batches# length of data / batch_size\n",
    "num_batch = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def to_variable(x,requires_grad=True):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x,requires_grad)\n",
    "\n",
    "counter = 0\n",
    "start_time = time.time()\n",
    "for current_epoch in tqdm(range(1,num_epoch+1)):\n",
    "    n_updates = 1\n",
    "\n",
    "    d_cost_avg = 0\n",
    "    g_cost_avg = 0\n",
    "    for idx in range(num_batch):\n",
    "\n",
    "        (batch_img, batch_map) = dataloader.get_batch()\n",
    "        batch_img = to_variable(batch_img,requires_grad=False) # [-1,3,h,w]\n",
    "        batch_map = to_variable(batch_map,requires_grad=False) # [-1,1,h,w]\n",
    "        real_labels = to_variable(torch.FloatTensor(np.ones(batch_size, dtype = float)),requires_grad=False)\n",
    "        fake_labels = to_variable(torch.FloatTensor(np.zeros(batch_size, dtype = float)),requires_grad=False)\n",
    "\n",
    "        if n_updates % 2 == 1:\n",
    "            #print('Training Discriminator...')\n",
    "            discriminator.zero_grad()\n",
    "            inp_d = torch.cat((batch_img,batch_map),1)\n",
    "            #print(inp_d.size())\n",
    "            outputs = discriminator(inp_d).squeeze()\n",
    "            d_real_loss = loss_function(outputs,real_labels)\n",
    "            #print('D_real_loss = ', d_real_loss.data[0])\n",
    "\n",
    "            #print(outputs)\n",
    "            real_score = outputs.data.mean()\n",
    "\n",
    "#            fake_map = generator(batch_img)\n",
    "#            inp_d = torch.cat((batch_img,fake_map),1)\n",
    "#            outputs = discriminator(inp_d)\n",
    "#            d_fake_loss = loss_function(outputs, fake_labels)\n",
    "#            print('D_fake_loss = ', d_fake_loss.data[0])\n",
    "            d_loss = torch.sum(torch.log(outputs))\n",
    "            #print(d_loss)\n",
    "            d_cost_avg += d_loss.data[0]\n",
    "\n",
    "            d_loss.backward()\n",
    "            d_optim.step()\n",
    "        else:\n",
    "            #print('Training Generator...')\n",
    "            generator.zero_grad()\n",
    "            fake_map = generator(batch_img)\n",
    "            inp_d = torch.cat((batch_img,fake_map),1)\n",
    "            outputs = discriminator(inp_d)\n",
    "            fake_score = outputs.data.mean()\n",
    "\n",
    "            g_gen_loss = loss_function(fake_map,batch_map)\n",
    "            g_dis_loss = -torch.log(outputs)\n",
    "            alpha = 0.05\n",
    "            g_loss = torch.sum(g_dis_loss + alpha * g_gen_loss)\n",
    "\n",
    "            g_cost_avg += g_loss.data[0]\n",
    "\n",
    "            g_loss.backward()\n",
    "            g_optim.step()\n",
    "\n",
    "        n_updates += 1\n",
    "\n",
    "        if (idx+1)%5 == 0:\n",
    "            print(\"Epoch [%d/%d], Step[%d/%d], d_loss: %.4f, g_loss: %.4f, D(x): %2.f, D(G(x)): %.2f, time: %4.4f\"\n",
    "                % (current_epoch, num_epoch, idx+1, num_batch, d_cost_avg, g_cost_avg,\n",
    "                real_score, fake_score, time.time()-start_time))\n",
    "        counter += 1\n",
    "\n",
    "    # Save weights every 3 epoch\n",
    "    if current_epoch % 3 == 0:\n",
    "        #predict(model=model, image_stimuli=validation_sample, numEpoch=current_epoch, pathOutputMaps=DIR_TO_SAVE)\n",
    "        print 'Epoch:', current_epoch, ' train_loss->', (d_cost_avg, g_cost_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def to_variable(x,requires_grad=True):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x,requires_grad)\n",
    "\n",
    "def show(img):\n",
    "    #print(img.shape)\n",
    "    pilTrans = transforms.ToPILImage()\n",
    "    pilImg = pilTrans(img)\n",
    "    s = np.array(pilImg)\n",
    "    plt.figure()\n",
    "    plt.imshow(s)\n",
    "    \n",
    "def save_gray(img, path):\n",
    "    pilTrans = transforms.ToPILImage()\n",
    "    pilImg = pilTrans(img)\n",
    "    print(path)\n",
    "    pilImg.save(path)\n",
    "    \n",
    "def predict(model, img, epoch, path):\n",
    "    to_tensor = transforms.ToTensor() # Transforms 0-255 numbers to 0 - 1.0.\n",
    "    im = to_tensor(img)\n",
    "    show(im)\n",
    "    inp = to_variable(im.unsqueeze(0), False)\n",
    "    #print(inp.size())\n",
    "    out = model(inp)\n",
    "    map_out = out.cpu().data.squeeze(0)\n",
    "    #show_gray(map_out)\n",
    "    \n",
    "    new_path = path + str(epoch) + \".png\"\n",
    "    save_gray(map_out, new_path)\n",
    "    \n",
    "    #s = np.array(Image.open(new_path))\n",
    "    #plt.figure()\n",
    "    #plt.imshow(s)\n",
    "    \n",
    "DIR_TO_SAVE = \"./generator_output/\"\n",
    "validation_sample = cv2.imread(\"COCO_val2014_000000143859.png\")\n",
    "predict(generator, validation_sample, current_epoch, DIR_TO_SAVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./generator_output/6.png\"\n",
    "s = np.array(Image.open(new_path))\n",
    "plt.figure()\n",
    "plt.imshow(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from generator import Generator\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "with open('vgg16.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    print(len(data))\n",
    "    G = Generator()\n",
    "    #print(G)\n",
    "    z = 'https://s3-us-west-2.amazonaws.com/jcjohns-models/vgg16-00b39a1b.pth'\n",
    "    f= 'https://download.pytorch.org/models/vgg16-397923af.pth'\n",
    "    G.load_state_dict(model_zoo.load_url(z))\n",
    "    print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999999642372\n",
      "6.28642737865e-09\n",
      "('Discriminator input', torch.Size([17, 4, 192, 256]))\n",
      "('Discriminator out ', Variable containing:\n",
      " 0.4530\n",
      " 0.4530\n",
      " 0.4531\n",
      " 0.4530\n",
      " 0.4530\n",
      " 0.4531\n",
      " 0.4530\n",
      " 0.4530\n",
      " 0.4530\n",
      " 0.4531\n",
      " 0.4529\n",
      " 0.4530\n",
      " 0.4530\n",
      " 0.4530\n",
      " 0.4530\n",
      " 0.4529\n",
      " 0.4530\n",
      "[torch.FloatTensor of size 17x1]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from discriminator import Discriminator\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "\n",
    "#D = Discriminator()\n",
    "x = Variable(torch.rand([17, 4, 192, 256]))\n",
    "print(x.data.max())\n",
    "print(x.data.min())\n",
    "model = Discriminator()\n",
    "print('Discriminator input', x.size()) #[-1, 4, 192, 256] because 4 comes from 3 color channel + salience layer.\n",
    "out = model(x)\n",
    "print('Discriminator out ', out) #[-1, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
